{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "> **Note**: sometimes your answer doesn't match one of \n",
    "> the options exactly. That's fine. \n",
    "> Select the option that's closest to your solution.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "In this homework, we'll build a model for predicting if we have an image of a bee or a wasp. \n",
    "For this, we will use the \"Bee or Wasp?\" dataset that was obtained from [Kaggle](https://www.kaggle.com/datasets/jerzydziewierz/bee-vs-wasp) and slightly rebuilt. \n",
    "\n",
    "You can download the dataset for this homework from [here](https://github.com/SVizor42/ML_Zoomcamp/releases/download/bee-wasp-data/data.zip):\n",
    "\n",
    "```bash\n",
    "wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/bee-wasp-data/data.zip\n",
    "unzip data.zip\n",
    "```\n",
    "\n",
    "In the lectures we saw how to use a pre-trained neural network. In the homework, we'll train a much smaller model from scratch. \n",
    "\n",
    "> **Note:** you will need an environment with a GPU for this homework. We recommend to use [Saturn Cloud](https://bit.ly/saturn-mlzoomcamp). \n",
    "> You can also use a computer without a GPU (e.g. your laptop), but it will be slower.\n",
    "\n",
    "\n",
    "### Data Preparation\n",
    "\n",
    "The dataset contains around 2500 images of bees and around 2100 images of wasps. \n",
    "\n",
    "The dataset contains separate folders for training and test sets. \n",
    "\n",
    "\n",
    "### Model\n",
    "\n",
    "For this homework we will use Convolutional Neural Network (CNN). Like in the lectures, we'll use Keras.\n",
    "\n",
    "You need to develop the model with following structure:\n",
    "\n",
    "* The shape for input should be `(150, 150, 3)`\n",
    "* Next, create a convolutional layer ([`Conv2D`](https://keras.io/api/layers/convolution_layers/convolution2d/)):\n",
    "    * Use 32 filters\n",
    "    * Kernel size should be `(3, 3)` (that's the size of the filter)\n",
    "    * Use `'relu'` as activation \n",
    "* Reduce the size of the feature map with max pooling ([`MaxPooling2D`](https://keras.io/api/layers/pooling_layers/max_pooling2d/))\n",
    "    * Set the pooling size to `(2, 2)`\n",
    "* Turn the multi-dimensional result into vectors using a [`Flatten`](https://keras.io/api/layers/reshaping_layers/flatten/) layer\n",
    "* Next, add a `Dense` layer with 64 neurons and `'relu'` activation\n",
    "* Finally, create the `Dense` layer with 1 neuron - this will be the output\n",
    "    * The output layer should have an activation - use the appropriate activation for the binary classification case\n",
    "\n",
    "As optimizer use [`SGD`](https://keras.io/api/optimizers/sgd/) with the following parameters:\n",
    "\n",
    "* `SGD(lr=0.002, momentum=0.8)`\n",
    "\n",
    "For clarification about kernel size and max pooling, check [Office Hours](https://www.youtube.com/watch?v=1WRgdBTUaAc).\n",
    "\n",
    "\n",
    "### Question 1\n",
    "\n",
    "Since we have a binary classification problem, what is the best loss function for us?\n",
    "\n",
    "* `mean squared error`\n",
    "* `binary crossentropy`\n",
    "* `categorical crossentropy`\n",
    "* `cosine similarity`\n",
    "\n",
    "> **Note:** since we specify an activation for the output layer, we don't need to set `from_logits=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Obtaining dependency information for scipy from https://files.pythonhosted.org/packages/6b/d4/d62ce38ba00dc67d7ec4ec5cc19d36958d8ed70e63778715ad626bcbc796/scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from scipy) (1.26.0)\n",
      "Downloading scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scipy\n",
      "Successfully installed scipy-1.11.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy \n",
    "# restart kernel afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace /\n",
      "PWD: /workspace\n",
      "File already exists. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "pushd /workspace\n",
    "echo \"PWD: \"$PWD\n",
    "path_zip=\"data.zip\"\n",
    "url_zip=\"https://github.com/SVizor42/ML_Zoomcamp/releases/download/bee-wasp-data/data.zip\"\n",
    "\n",
    "if [ ! -f \"$path_zip\" ]; then\n",
    "    # use curl for downloading\n",
    "    echo \"File not found! Downloading it\"\n",
    "    curl -LJO -o $path_zip $url_zip\n",
    "    unzip -q $path_zip\n",
    "else\n",
    "    echo \"File already exists. Skipping download.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 06:38:10.636038: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-20 06:38:11.136045: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-20 06:38:11.136091: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-20 06:38:11.137853: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-20 06:38:11.329147: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 06:38:16.882109: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-20 06:38:16.910267: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-20 06:38:16.910420: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-20 06:38:16.914365: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-20 06:38:16.914407: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-20 06:38:16.914422: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-20 06:38:17.824826: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-20 06:38:17.824931: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-20 06:38:17.824948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-11-20 06:38:17.825013: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-20 06:38:17.825055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 3554 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')],\n",
       " '/device:GPU:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "\n",
    "#https://www.tensorflow.org/versions/r2.8/api_docs/python/tf/config/experimental/enable_op_determinism\n",
    "seed = 1234\n",
    "tf.keras.utils.set_random_seed(seed)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "tf.test.is_built_with_gpu_support(), tf.config.list_physical_devices('GPU'), tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 4050 Laptop GPU (UUID: GPU-32a8e098-cd49-63b9-94ae-5b7a033749f2)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi --list-gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model(seed, shape=(150, 150, 3)):\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.keras.utils.set_random_seed(seed)\n",
    "    #tf.config.experimental.enable_op_determinism()\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=shape),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 1\n",
    "\n",
    "binary crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 2\n",
    "\n",
    "What's the number of parameters in the convolutional layer of our model? You can use the `summary` method for that. \n",
    "\n",
    "* 1 \n",
    "* 65\n",
    "* 896\n",
    "* 11214912\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 06:38:18.213061: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-20 06:38:18.213191: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-20 06:38:18.213210: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-20 06:38:18.213911: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-20 06:38:18.213936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-11-20 06:38:18.214044: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-20 06:38:18.214074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3554 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 74, 74, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 175232)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11215873 (42.79 MB)\n",
      "Trainable params: 11215873 (42.79 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = simple_model(seed)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 2\n",
    "\n",
    "896"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Generators and Training\n",
    "\n",
    "For the next two questions, use the following data generator for both train and test sets:\n",
    "\n",
    "```python\n",
    "ImageDataGenerator(rescale=1./255)\n",
    "```\n",
    "\n",
    "* We don't need to do any additional pre-processing for the images.\n",
    "* When reading the data from train/test directories, check the `class_mode` parameter. Which value should it be for a binary classification problem?\n",
    "* Use `batch_size=20`\n",
    "* Use `shuffle=True` for both training and test sets. \n",
    "\n",
    "For training use `.fit()` with the following params:\n",
    "\n",
    "```python\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 3\n",
    "\n",
    "What is the median of training accuracy for all the epochs for this model?\n",
    "\n",
    "* 0.20\n",
    "* 0.40\n",
    "* 0.60\n",
    "* 0.80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height = 150\n",
    "image_width = 150\n",
    "batch_size = 20\n",
    "train_dir = '/workspace/data/train/'\n",
    "test_dir = '/workspace/data/test/'\n",
    "\n",
    "\n",
    "\n",
    "def get_train_val_ds(\n",
    "    train_dir,\n",
    "    val_dir,\n",
    "    image_height,\n",
    "    image_width,\n",
    "    batch_size,\n",
    "    seed,\n",
    "):\n",
    "    tf.keras.utils.set_random_seed(seed)\n",
    "    train_gen = ImageDataGenerator(rescale=1./255)\n",
    "    val_gen = ImageDataGenerator(rescale=1./255)\n",
    "    train_ds = train_gen.flow_from_directory(\n",
    "        train_dir,\n",
    "        # seed=seed,\n",
    "        target_size=(image_height, image_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=True,\n",
    "        )\n",
    "    val_ds = val_gen.flow_from_directory(\n",
    "        test_dir,\n",
    "        # seed=seed,\n",
    "        target_size=(image_height, image_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=True,\n",
    "        )\n",
    "    # print(train_ds.class_indices)\n",
    "    return train_ds, val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cpu_count = multiprocessing.cpu_count()\n",
    "workers = min(1, cpu_count - 1)\n",
    "workers = max(workers, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(learning_rate=0.002, momentum=0.8)\n",
    "loss = binary_crossentropy\n",
    "metrics = ['accuracy']\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n",
      "Found 918 images belonging to 2 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 06:38:23.266711: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2023-11-20 06:38:25.220073: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdf64353790 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-20 06:38:25.220181: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4050 Laptop GPU, Compute Capability 8.9\n",
      "2023-11-20 06:38:25.347724: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 11s 41ms/step - loss: 0.6816 - accuracy: 0.5662 - val_loss: 0.6479 - val_accuracy: 0.6111\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 8s 44ms/step - loss: 0.6331 - accuracy: 0.6358 - val_loss: 0.5979 - val_accuracy: 0.6852\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 7s 39ms/step - loss: 0.5784 - accuracy: 0.6973 - val_loss: 0.5441 - val_accuracy: 0.7462\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 7s 39ms/step - loss: 0.5440 - accuracy: 0.7327 - val_loss: 0.5355 - val_accuracy: 0.7266\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 8s 42ms/step - loss: 0.5094 - accuracy: 0.7590 - val_loss: 0.5385 - val_accuracy: 0.7364\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 8s 42ms/step - loss: 0.4897 - accuracy: 0.7808 - val_loss: 0.5180 - val_accuracy: 0.7603\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 8s 44ms/step - loss: 0.4589 - accuracy: 0.7985 - val_loss: 0.4985 - val_accuracy: 0.7691\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 8s 42ms/step - loss: 0.4447 - accuracy: 0.8083 - val_loss: 0.4980 - val_accuracy: 0.7549\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 8s 42ms/step - loss: 0.4109 - accuracy: 0.8249 - val_loss: 0.5310 - val_accuracy: 0.7495\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 8s 42ms/step - loss: 0.3903 - accuracy: 0.8300 - val_loss: 0.4828 - val_accuracy: 0.7756\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(seed)\n",
    "train_ds, val_ds = get_train_val_ds(\n",
    "    train_dir=train_dir,\n",
    "    val_dir=test_dir,\n",
    "    batch_size=batch_size,\n",
    "    image_height=image_height, \n",
    "    image_width=image_width,\n",
    "    seed=seed,\n",
    ")\n",
    "model = simple_model(seed)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "history = model.fit(\n",
    "    train_ds, \n",
    "    epochs=epochs, \n",
    "    validation_data=val_ds, \n",
    "    workers=workers, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.median(history.history['accuracy']), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "0.80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 4\n",
    "\n",
    "What is the standard deviation of training loss for all the epochs for this model?\n",
    "\n",
    "* 0.031\n",
    "* 0.061\n",
    "* 0.091\n",
    "* 0.131\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.std(history.history['loss']), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 4\n",
    "\n",
    "0.031"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Data Augmentation\n",
    "\n",
    "For the next two questions, we'll generate more data using data augmentations. \n",
    "\n",
    "Add the following augmentations to your training data generator:\n",
    "\n",
    "* `rotation_range=50,`\n",
    "* `width_shift_range=0.1,`\n",
    "* `height_shift_range=0.1,`\n",
    "* `zoom_range=0.1,`\n",
    "* `horizontal_flip=True,`\n",
    "* `fill_mode='nearest'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_ds(\n",
    "    train_dir,\n",
    "    val_dir,\n",
    "    image_height,\n",
    "    image_width,\n",
    "    batch_size,\n",
    "    seed,\n",
    "):\n",
    "    tf.keras.utils.set_random_seed(seed)\n",
    "    train_gen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=50,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        )\n",
    "    val_gen = ImageDataGenerator(rescale=1./255)\n",
    "    train_ds = train_gen.flow_from_directory(\n",
    "        train_dir,\n",
    "        # seed=seed,\n",
    "        target_size=(image_height, image_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=True,\n",
    "        )\n",
    "    val_ds = val_gen.flow_from_directory(\n",
    "        test_dir,\n",
    "        # seed=seed,\n",
    "        target_size=(image_height, image_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=True,\n",
    "        )\n",
    "    # print(train_ds.class_indices)\n",
    "    return train_ds, val_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 5 \n",
    "\n",
    "Let's train our model for 10 more epochs using the same code as previously.\n",
    "> **Note:** make sure you don't re-create the model - we want to continue training the model\n",
    "we already started training.\n",
    "\n",
    "What is the mean of test loss for all the epochs for the model trained with augmentations?\n",
    "\n",
    "* 0.18\n",
    "* 0.48\n",
    "* 0.78\n",
    "* 0.108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n",
      "Found 918 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "184/184 [==============================] - 13s 66ms/step - loss: 0.5031 - accuracy: 0.7626 - val_loss: 0.5195 - val_accuracy: 0.7527\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 12s 64ms/step - loss: 0.4998 - accuracy: 0.7650 - val_loss: 0.4758 - val_accuracy: 0.7821\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 13s 66ms/step - loss: 0.4877 - accuracy: 0.7773 - val_loss: 0.5071 - val_accuracy: 0.7516\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 13s 66ms/step - loss: 0.4816 - accuracy: 0.7745 - val_loss: 0.5298 - val_accuracy: 0.7484\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 13s 68ms/step - loss: 0.4793 - accuracy: 0.7846 - val_loss: 0.4731 - val_accuracy: 0.7789\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 13s 68ms/step - loss: 0.4793 - accuracy: 0.7770 - val_loss: 0.4684 - val_accuracy: 0.7854\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 14s 70ms/step - loss: 0.4672 - accuracy: 0.7857 - val_loss: 0.5106 - val_accuracy: 0.7680\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 13s 65ms/step - loss: 0.4658 - accuracy: 0.7873 - val_loss: 0.4852 - val_accuracy: 0.7821\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 13s 69ms/step - loss: 0.4668 - accuracy: 0.7846 - val_loss: 0.4465 - val_accuracy: 0.8028\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 13s 68ms/step - loss: 0.4625 - accuracy: 0.7871 - val_loss: 0.5614 - val_accuracy: 0.7516\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(seed)\n",
    "train_ds, val_ds = get_train_val_ds(\n",
    "    train_dir=train_dir,\n",
    "    val_dir=test_dir,\n",
    "    batch_size=batch_size,\n",
    "    image_height=image_height, \n",
    "    image_width=image_width,\n",
    "    seed=seed,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds, \n",
    "    epochs=10, \n",
    "    validation_data=val_ds, \n",
    "    workers=workers, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.mean(history.history['val_loss']), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 5\n",
    "\n",
    "0.48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 6\n",
    "\n",
    "What's the average of test accuracy for the last 5 epochs (from 6 to 10)\n",
    "for the model trained with augmentations?\n",
    "\n",
    "* 0.38\n",
    "* 0.58\n",
    "* 0.78\n",
    "* 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7854030728340149,\n",
       " 0.7679738402366638,\n",
       " 0.7821350693702698,\n",
       " 0.8028322458267212,\n",
       " 0.7516340017318726]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['val_accuracy'][-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.mean(history.history['val_accuracy'][-5:]), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 6\n",
    "\n",
    "0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Submit the results\n",
    "\n",
    "- Submit your results here: https://forms.gle/5sjtM3kzY9TmLmU17\n",
    "- If your answer doesn't match options exactly, select the closest one\n",
    "- You can submit your solution multiple times. In this case, only the last submission will be used\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deadline\n",
    "\n",
    "The deadline for submitting is November 20 (Monday), 23:00 CEST. After that the form will be closed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
